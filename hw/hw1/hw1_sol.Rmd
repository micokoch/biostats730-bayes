---
title: "Applied Bayesian modeling - HW1"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

Score: The maximum number of points in this HW is 15 points, with 3 points extra credit. For calculating a final HW grade, the points will be rescaled to a maximum score of (15+3)/15*100% = 120%. 

What to hand in: For exercise 2, we need an Rmd and a knitted pdf. 
You may hand in the answer to exercise 1 in a different output form as long as it's legible (i.e., no difficult-to-read picture of handwritten notes). 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Exercise 1: Breast cancer and mammogram screening [5 pts]

This exercise is about the material in module 2. 

Background information: 
Gerd Gegerenzer explained to 24 physicians:

- For early detection of breast cancer, women are encouraged to have routine screening, even if they have no symptoms.
- Imagine you conduct such screening using mammography
- The following information is available about asymptomatic women aged 40 to 50 in your region 			who have mammography screening:

  -  The probability an asymptomatic woman has breast cancer is 0.8\%.
  - If she has breast cancer, the probability is 90\% that she has a positive mammogram.
  - If she does not have breast cancer, the probability is 7\% that she still has a positive mammogram.

- Suppose a woman has a positive mammogram: What is the probability she actually has breast cancer?
- Physicians' answers ranged from about 1\% to about 90\%.

Use Bayes' rule to obtain the probability that a woman with a postive mammogram has breast cancer, using the information provided above. Show working, meaning to write out how you obtained probabilities that are not given in the information.

### Answer: 

When given a question in words, consider first introducing some notation, to then define the outcome of interest and consider what information is given.

- Let 
  - $C$ be the breast cancer outcome ($C=1$ if the woman has breast cancer, 0 otherwise),
  - $M$ the outcome of the mammogram ($M=1$ if the mammogram is positive, 0 otherwise). 
-  What do we want to know?  
$P(C=1|M=1)$.
- What information do we have?
  - The probability a woman has breast cancer is 0.8\%.   
			$\Rightarrow P(C=1) = 0.008$.
  - If she has breast cancer, the probability is 90\% that she has a positive mammogram  $\Rightarrow P(M=1|C=1) = 0.9$.
  - If she does not have breast cancer, the probability is 7\% that she still has a positive mammogram  $\Rightarrow P(M=1|C=0) = 0.07$.  

- Putting it all together:
		\begin{eqnarray*}
			Prob(C=1) &=& 0.008,\\
			Prob(M=1|C=1) &=& 0.9,\\
			Prob(M=1|C=0) &=& 0.07.
		\end{eqnarray*}
- Bayes' rule says that the prob. that the woman with a positive mammogram has breast cancer is
		\begin{eqnarray*}
			& Prob(C=1|M=1) = \frac{Prob(M=1|C=1)Prob(C=1)}{Prob(M=1)},\\
			&= \frac{Prob(M=1|C=1)Prob(C=1)}{\sum_{c=0}^1 Prob(M=1|C=c)Prob(C=c)} 
			=\frac{0.9\times0.008}{0.9\times0.008+0.07\times0.992}=9.4\%.
		\end{eqnarray*}
Note that here we carry out Bayesian updating of the prior probability that a woman has cancer based on evidence (a + mammogram). 


## Exercise 2: posteriors when everything's normal
This exercise is about module 3. You may find the R notebook with module 3 helpful. 

We continue with the radon data set. (Note that I read in and process the data in the HW Rmd but don't print out the code).
```{r, echo = F, message = FALSE, results = F}
# house level data
d <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/srrs2.dat"), header=T, sep=",")

# deal with zeros, select what we want, make a fips (county) variable to match on 
d <- d %>% 
  mutate(activity = ifelse(activity==0, 0.1, activity)) %>% 
  mutate(fips = stfips * 1000 + cntyfips) %>%   
  dplyr::select(fips, state, county, floor, activity)

# county level data
cty <- read.table(url("http://www.stat.columbia.edu/~gelman/arm/examples/radon/cty.dat"), header = T, sep = ",")
cty <- 
  cty %>% 
  mutate(fips = 1000 * stfips + ctfips) %>% 
  dplyr::select(fips, Uppm) %>%
  rename(ura_county = (Uppm))

dmn <- d %>% 
  filter(state=="MN") %>% # Minnesota data only
  dplyr::select(fips, county, floor, activity) %>% 
  left_join(cty) 

y <- log(dmn$activity)
```

We will carry out Bayesian inference assuming a normal likelihood and prior:

$y_i|\mu, \sigma^2 \sim N(\mu, \sigma^2)$, independent;   

$\mu \sim N(m_0,s_{\mu0}^2)$

<!-- $ \mu|\bm{y}, \sigma^2 \sim N\left(\frac{m_0/s_{\mu0}^2 +n\cdot\bar{y}/\sigma^2}{1/s_{\mu0}^2+n/\sigma^2},\frac{1}{1/s_{\mu0}^2+n/\sigma^2}\right)$ -->

with prior mean parameters $\mu_0 = 0$ and $s_{\mu0} = 0.1$ and $\sigma = s\{y\}$.  
$\bar{y}$ is given by the log-radon data. 

### Exercise 2a [5 pts, with additional 1 pt extra credit]
Use the radon data and obtain the posterior distribution $p(\mu|\mathbf{y})$, using the prior and likelihood as specified above. Use the posterior to produce the following outputs:  
(i) one plot with the prior, posterior, and likelihood function;  
(ii) a point estimate, 95% credible interval, and 80% credible interval.  
(iii) Interpretation of the 80% credible interval. 

Extra credit question (1 pt): Can you calculate the posterior probability that $\mu$ is greater than $\bar{y}$? If yes, report it. If not, why not?

#### Answer: 

Fix prior mean and prior sd
```{r}
mu0 <- 0 # prior mean 
sigma.mu0 <- 0.1  # prior sd
```

Information that depends on the data 
```{r}
ybar <- mean(y)
sd.y <- sd(y)
n <- length(y)
sigma <- sd.y
# sd for ybar follows from sigma
sd.ybar <- sigma/sqrt(n) # needed if you want to use the automated grid option
```
Posterior mean and variance:
```{r, echo = F}
mupost.mean <- (mu0/(sigma.mu0^2) + n*ybar/(sigma^2))/(1/(sigma.mu0^2) + n/(sigma^2))
mupost.sd <- sqrt(1/(1/(sigma.mu0^2)+n/(sigma^2)))
```

Plot
```{r, echo = F}
mupost.mean <- (mu0/(sigma.mu0^2) + n*ybar/(sigma^2))/(1/(sigma.mu0^2) + n/(sigma^2))
mupost.sd <- sqrt(1/(1/(sigma.mu0^2)+n/(sigma^2)))
# hard-coded grid 
# mugrid <- seq(1, 1.5, length.out = 3000)
# or, based on parameters 
mugrid <- seq(
   min(mu0 - 3*sigma.mu0, mupost.mean - 3*mupost.sd, ybar - 3*sd.ybar),
   max(mu0 + 3*sigma.mu0, mupost.mean + 3*mupost.sd, ybar + 3*sd.ybar),
  length.out = 3000)
prior.dens <- dnorm(x = mugrid, mean = mu0 , sd = sigma.mu0)
like.dens <- dnorm(x = mugrid, mean = ybar, sd = sd.ybar)
post.dens <- dnorm(x = mugrid, mean = mupost.mean, sd = mupost.sd)
toplot <- tibble(
  dens = c(prior.dens,  like.dens, post.dens),
  dtype = rep(c("prior", "like", "post"), each = length(mugrid)),
  mugrid = rep(mugrid, 3))

toplot %>%
  mutate(dtype = factor(dtype, levels = c("like", "prior", "post"))) %>%
  ggplot(aes(
    x = mugrid,
    y = dens,
    col = dtype,
    lty = dtype
  ))   +
  geom_line(size = 1.5) +
  theme_minimal() +
  ylab("Density") +
  xlab(expression(mu)) +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    text = element_text(size = 20)
  ) 
```

Point estimate:
```{r}
mupost.mean # posterior mean
```

95% CI:
```{r}
qnorm(c(0.025, 0.975), mean = mupost.mean, sd = mupost.sd) # 95% quantile-based CI
```

80% CI:
```{r}
qnorm(c(0.1, 0.9), mean = mupost.mean, sd = mupost.sd) # 80% quantile-based CI
```
Interpretation of the 80%CI: there is an 80% probability that $\mu$ is between 1.10 and 1.17, where $\mu$ here refers to mean log-radon.


Probability that $\mu$ is greater than $\bar{y}$ is 0.04%.
```{r}
(1 - pnorm(ybar, mean = mupost.mean, sd = mupost.sd) )
```



### Exercise 2b [5pts]
Let's call the data set used so far data set 1. Suppose there is a second radon data set, referred to as data set 2, that has the same $\bar{y}$ and $s\{y\}$ as data set 1. What differs between the two data sets is that data set 2 has sample size $n = 4635$, which is 5 times the sample size of data set set 1 (with $n = 927$).

Obtain the posterior using data set 2, and produce the same outputs (i) and (ii) from exercise a. (No need to interpret  the CI).

#### Answer

Updating what changes:
```{r}
n <- 5*length(y)
sd.ybar <- sigma/sqrt(n)
mupost.mean <- (mu0/(sigma.mu0^2) + n*ybar/(sigma^2))/(1/(sigma.mu0^2) + n/(sigma^2))
mupost.sd <- sqrt(1/(1/(sigma.mu0^2)+n/(sigma^2)))
```


```{r, echo = F}
# hard-coded grid 
# mugrid <- seq(1, 1.5, length.out = 3000)
# or, based on parameters 
mugrid <- seq(
   min(mu0 - 3*sigma.mu0, mupost.mean - 3*mupost.sd, ybar - 3*sd.ybar),
   max(mu0 + 3*sigma.mu0, mupost.mean + 3*mupost.sd, ybar + 3*sd.ybar),
  length.out = 3000)
prior.dens <- dnorm(x = mugrid, mean = mu0 , sd = sigma.mu0)
like.dens <- dnorm(x = mugrid, mean = ybar, sd = sd.ybar)
post.dens <- dnorm(x = mugrid, mean = mupost.mean, sd = mupost.sd)
toplot <- tibble(
  dens = c(prior.dens,  like.dens, post.dens),
  dtype = rep(c("prior", "like", "post"), each = length(mugrid)),
  mugrid = rep(mugrid, 3))

toplot %>%
  mutate(dtype = factor(dtype, levels = c("like", "prior", "post"))) %>%
  ggplot(aes(
    x = mugrid,
    y = dens,
    col = dtype,
    lty = dtype
  ))   +
  geom_line(size = 1.5) +
  theme_minimal() +
  ylab("Density") +
  xlab(expression(mu)) +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    text = element_text(size = 20)
  ) 
```

Point estimate:
```{r}
mupost.mean # posterior mean
qnorm(c(0.025, 0.975), mean = mupost.mean, sd = mupost.sd) # 95% quantile-based CI
qnorm(c(0.1, 0.9), mean = mupost.mean, sd = mupost.sd) # 80% quantile-based CI
(1 - pnorm(ybar, mean = mupost.mean, sd = mupost.sd)) # prob that mu is greater than ybar
```

### Exercise 2c [extra credit 2pts]
Briefly comment on the differences in posteriors between exercises a and b: in which setting is the posterior more data-driven, closer to $\bar{y}$? Is that what you expected?

#### Answer 
The posterior is closer to $\bar{y}$, more data driven, in (b). That's what I expected because there is more data to inform the posterior in (b).  
 